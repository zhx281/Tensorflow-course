{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Happy_or_Sad_v1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TM-G__WCtznD",
        "colab_type": "text"
      },
      "source": [
        "# Prefix\n",
        "In this notebook, we will be looking at the happy-or-sad dataset and create a model that would predict if the person is happy or sad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgeMt_Grwg_G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os, zipfile"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg3t2KBEu_Aq",
        "colab_type": "text"
      },
      "source": [
        "# Step 1: Loading the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xCrWIXLtx1k",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1375ced2-f7ff-4d31-f21f-ce9bed3cefcb"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\" \\\n",
        "    -O \"/tmp/happy-or-sad.zip\"\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/tmp/happy-or-sad.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp/h-or-s\")\n",
        "zip_ref.close()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-06-17 19:09:18--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.194.128, 2404:6800:4003:c04::80\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.194.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2670333 (2.5M) [application/zip]\n",
            "Saving to: ‘/tmp/happy-or-sad.zip’\n",
            "\n",
            "\r/tmp/happy-or-sad.z   0%[                    ]       0  --.-KB/s               \r/tmp/happy-or-sad.z 100%[===================>]   2.55M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2019-06-17 19:09:19 (191 MB/s) - ‘/tmp/happy-or-sad.zip’ saved [2670333/2670333]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJwcwkhnyaXG",
        "colab_type": "text"
      },
      "source": [
        "# Step 2: Building the Model\n",
        "We are going to build the model with multiply convolutional layers and maxpooling layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsI5zC6Kynva",
        "colab_type": "text"
      },
      "source": [
        "### Custom Callbacks function\n",
        "A custom callbacks function stop the training at 99.9% accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS7kNJrdvKOs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# creating callbacks to stop training at 99.9%\n",
        "class myCallbacks(tf.keras.callbacks.Callback):\n",
        "  def __init__(self, desired_accuracy=.999):\n",
        "    self.d_acc = desired_accuracy\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if logs.get('acc') > self.d_acc:\n",
        "      print('\\nAccuracy above {:.2f}%, Training STOPPED!'.format(self.d_acc))\n",
        "      self.model.stop_training = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWoJBzXjy28Z",
        "colab_type": "text"
      },
      "source": [
        "### Building the Convolutional Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJshEIZ6wdRw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dhEMOnO3y-YA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# helper function for creating multiply conv2d and maxpooling layers\n",
        "def multi_conv(x, size):\n",
        "  assert(isinstance(size, list)), 'size arg must be a list containing integers'\n",
        "  for s in size:\n",
        "    l = Conv2D(s, (3,3), activation='relu')(x)\n",
        "    l = MaxPooling2D(2,2)(l)\n",
        "  return l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HW7yZ9WZw6lU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "f5c4b040-ecaa-44ee-9195-55d5dd92e2dd"
      },
      "source": [
        "# building the model with multi convolutional layers with maxpooling\n",
        "in_x = Input(shape=(300, 300, 3))\n",
        "X = multi_conv(in_x, [16, 32, 64, 32, 64, 32])\n",
        "X = Flatten()(X)\n",
        "X = Dense(512, activation='relu')(X)\n",
        "X = Dense(1, activation='sigmoid')(X)\n",
        "\n",
        "model = Model(in_x, X)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0617 19:09:47.010967 139731058648960 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 300, 300, 3)]     0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 298, 298, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 149, 149, 32)      0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 710432)            0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               363741696 \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 363,743,105\n",
            "Trainable params: 363,743,105\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjciuWqxyE2A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "adca9055-16c9-41ba-e363-27b452b0540e"
      },
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0617 19:09:51.941649 139731058648960 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUjiLN4gzied",
        "colab_type": "text"
      },
      "source": [
        "# Step 3: Preprocessing the Data\n",
        "We are going to use the ImageDataGenerator function from keras.preprocessing to how us easily preprocess the image data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FrRaTSvzdDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXy7G0120H2N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e946ee67-58e8-46d0-94d0-ca78b8598eb9"
      },
      "source": [
        "train_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory('/tmp/h-or-s',\n",
        "                                                    target_size=(300, 300),\n",
        "                                                    batch_size=10,\n",
        "                                                    class_mode='binary')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 80 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQNuGUKn1Djq",
        "colab_type": "text"
      },
      "source": [
        "# Step 4: Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7elPiDO00xfl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "3c3b36f6-af9f-451b-84ea-4122693e884e"
      },
      "source": [
        "# setting callbacks\n",
        "callbacks = myCallbacks()\n",
        "# training the model\n",
        "model.fit_generator(train_generator, \n",
        "                    epochs=15,\n",
        "                    steps_per_epoch=2,\n",
        "                    verbose=1,\n",
        "                    callbacks=[callbacks])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "2/2 [==============================] - 12s 6s/step - loss: 100.1854 - acc: 0.7500\n",
            "Epoch 2/15\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 89.6502 - acc: 0.4000\n",
            "Epoch 3/15\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 14.9197 - acc: 0.3000\n",
            "Epoch 4/15\n",
            "2/2 [==============================] - 0s 99ms/step - loss: 0.4519 - acc: 0.8500\n",
            "Epoch 5/15\n",
            "1/2 [==============>...............] - ETA: 0s - loss: 0.0029 - acc: 1.0000\n",
            "Accuracy above 1.00%, Training STOPPED!\n",
            "2/2 [==============================] - 0s 150ms/step - loss: 0.0014 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f15620cba90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    }
  ]
}